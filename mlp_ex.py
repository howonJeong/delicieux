# -*- coding: utf-8 -*-
"""MLP EX

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uhyzn1nIGGhMDjzeJYds8EHgFuVgSES9

# **MLP**
"""

import torch 
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim # optimizer
from torchvision import datasets, transforms  #dataset
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from tqdm.notebook import tqdm

"""# **HyperParameter**

   - Parameter 
     * Parameter(decided in the model) 
     * teachable weight, bias 
   - HyperParameter 
     * set by user while modeling
"""

epochs= 10
batch_size= 64
lr= 1e-4
dropout= 0.2
n_class= 10

# seed 
seed = 2891
torch.manual_seed = seed  #for same inputs

"""# **2. GPU**
 - cpu: max -> 24core 
 - gpu: expertising in floating point
 - Deep learning is basically three arithmetic operations using matrix, so gpu is recommended 
"""

! nvidia-smi
device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)

"""# **3. Data preaparation**
   - Dataset  
     * Dataset class is process of forming the entire dataset.
     * __init__(self)
     * __get_item__(self, index)
     *__len__(self)
   - DataLoader 
     * Dataloader class is for making mini batch based on the batch for deep learning model learning.
"""

train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transforms.ToTensor())
test_dataset = datasets.MNIST('./data', train=False, transform=transforms.ToTensor())
sample_data, label = train_dataset[0]

plt.imshow(sample_data.reshape((28, 28)), cmap='gray')
print(label)

train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
print(f"[Dataset] train: {len(train_dataset)}, test: {len(test_dataset)}")
print(f"[DataLoader] train: {len(train_dataloader)}, test: {len(test_dataloader)}")

"""# **4. model making**

- nn.Linear: module processing linear transform using stored weight&bias
   - nn.Softmax: adjusted between 0 and 1 in order to show expectation probability for each class of the model.
   - nn.Dropout: one of the solution of overfitting. excluding some parameters for learing.
   - F.relu: f(x) = max(x, 0)
"""

class MLP(nn.Module):
    def __init__(self, n_class, dropout):
        super(MLP, self).__init__()
        # input is 28x28
        # need for flatten ==> 784
        self.linear1= nn.Linear(784, 512) # hidden size of first layer -> input: 784, output:512 and emit to hidden
        self.linear2= nn.Linear(512, 512)
        self.classifier_layer= nn.Linear(512, n_class) # 512 for input, aka last hidden size -> changing the number of class as num_class
        self.softmax= nn.Softmax(dim=1)      
        self.dropout= nn.Dropout(dropout)
    def forward(self, x):
        x= self.dropout(F.relu(self.linear1(x.view(-1, 784))))
        x= self.dropout(F.relu(self.linear2(x)))
        output= self.classifier_layer(x)
        return self.softmax(output)

#model!!!!!!!!!!!
model = MLP(n_class, dropout).to(device)

print("[Model Structure]")
print(model)
print()
print("[Linear1  weights]")
print(model.linear1.weight.size())
print()
print("[Linear1  bias]")
print(model.linear1.bias.size())

"""**5. Model Training**

* Model Training
  -  finding the best value of parameter (a.k.a weights, bias) in the model
* process? 
  - Forward 
  - Backward
  - Optimizer.step()

* Optimizer?
 - Model Learning = optimization task.
 - Optimizing is series of processing to find lowest value of loss function.
 - All optimizer is processed in step() method.
"""

loss_fn= nn.CrossEntropyLoss()
optimizer= optim.Adam(model.parameters(), lr=lr)

tot_train_loss= []
model.train()
for e in range(1, epochs+1):
    print(f"============= [Epochs] {e}/{epochs} =============")
    train_loss= 0.0
    for datas, labels in tqdm(train_dataloader):
        datas= datas.to(device)
        labels= labels.to(device)

        output= model(datas)
        loss= loss_fn(output, labels)
        train_loss += loss.item()

        optimizer.zero_grad()        
        loss.backward()
        optimizer.step()
    tot_train_loss.append(train_loss/len(train_dataloader))
    print(f"Loss: {train_loss/len(train_dataloader):.6f}")

    # iniciated to observe performance growth in ever epochs
    with torch.no_grad(): # autograd engine turn off
        model.eval() # dropout deactivated
        test_acc= 0.0
        for datas, labels in tqdm(test_dataloader):
            
            datas= datas.to(device)
            labels= labels.to(device)
            
            output= model(datas)
            
            preds= torch.argmax(output, dim=1)
            test_acc+= preds.eq(labels).sum()

    print(f"[Epoch] {e}, [Test Result] {(test_acc/len(test_dataloader.dataset))*100:.3f}%")

"""**6. Model Testing**
* to show that model is taught well.
"""

with torch.no_grad():
    model.eval()
    test_acc= 0.0
    for datas, labels in tqdm(test_dataloader):
        
        datas= datas.to(device)
        labels= labels.to(device)
        
        output= model(datas)
        
        preds= torch.argmax(output, dim=1)
        test_acc+= preds.eq(labels).sum()

print(f"[Test Result] {(test_acc/len(test_dataloader.dataset))*100:.3f}%")